{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 - Supervised Learning - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83620, 49)\n",
      "(83620, 1)\n"
     ]
    }
   ],
   "source": [
    "state = 'GA'\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "load_dir = current_dir + '\\\\module1_data\\\\' + state\n",
    "\n",
    "#uncomment 1\n",
    "# data = 'Xstate_f194.npy' #original\n",
    "# data = 'Xforest_f102.npy' #random forest feature importance\n",
    "data = 'Xpca_f194_c049_v9713.npy' #principle components\n",
    "\n",
    "X = np.load(load_dir + '\\\\' + data)\n",
    "print(X.shape)\n",
    "\n",
    "y = np.load(load_dir + '\\\\ystate.npy')\n",
    "y = y - 1\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (58533, 49)\n",
      "y train: (58533, 1)\n",
      "X test:  (25086, 49)\n",
      "y test:  (25086, 1)\n"
     ]
    }
   ],
   "source": [
    "#DO NOT CHANGE\n",
    "\n",
    "#split into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, train_size=0.70, random_state=0, shuffle=True)\n",
    "\n",
    "print('X train:', X_train.shape)\n",
    "print('y train:', y_train.shape)\n",
    "print('X test: ', X_test.shape)\n",
    "print('y test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3.94, NNZs: 49, Bias: -5.000000, T: 58533, Avg. loss: 0.001406\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.41, NNZs: 49, Bias: -4.000000, T: 117066, Avg. loss: 0.001425\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.02, NNZs: 49, Bias: -5.000000, T: 175599, Avg. loss: 0.001527\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.85, NNZs: 49, Bias: -5.000000, T: 234132, Avg. loss: 0.001502\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.19, NNZs: 49, Bias: -5.000000, T: 292665, Avg. loss: 0.001502\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.09, NNZs: 49, Bias: -6.000000, T: 351198, Avg. loss: 0.001470\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 6 epochs took 0.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.04, NNZs: 49, Bias: -3.000000, T: 58533, Avg. loss: 1.278977\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 10.04, NNZs: 49, Bias: -3.000000, T: 117066, Avg. loss: 1.272975\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.44, NNZs: 49, Bias: -2.000000, T: 175599, Avg. loss: 1.264517\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.92, NNZs: 49, Bias: -2.000000, T: 234132, Avg. loss: 1.269477\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.49, NNZs: 49, Bias: -2.000000, T: 292665, Avg. loss: 1.266303\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.10, NNZs: 49, Bias: 0.000000, T: 351198, Avg. loss: 1.270422\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.71, NNZs: 49, Bias: 3.000000, T: 409731, Avg. loss: 1.274191\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9.91, NNZs: 49, Bias: -2.000000, T: 468264, Avg. loss: 1.282099\n",
      "Total training time: 0.16 seconds.\n",
      "Convergence after 8 epochs took 0.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 8.77, NNZs: 49, Bias: -2.000000, T: 58533, Avg. loss: 1.319309\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 10.09, NNZs: 49, Bias: 2.000000, T: 117066, Avg. loss: 1.296832\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.27, NNZs: 49, Bias: 1.000000, T: 175599, Avg. loss: 1.303043\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.57, NNZs: 49, Bias: -1.000000, T: 234132, Avg. loss: 1.299376\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.27, NNZs: 49, Bias: 2.000000, T: 292665, Avg. loss: 1.307355\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.98, NNZs: 49, Bias: 2.000000, T: 351198, Avg. loss: 1.310758\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 11.74, NNZs: 49, Bias: -1.000000, T: 409731, Avg. loss: 1.304901\n",
      "Total training time: 0.14 seconds.\n",
      "Convergence after 7 epochs took 0.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 9.68, NNZs: 49, Bias: -5.000000, T: 58533, Avg. loss: 0.404301\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.74, NNZs: 49, Bias: -4.000000, T: 117066, Avg. loss: 0.407754\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.56, NNZs: 49, Bias: -6.000000, T: 175599, Avg. loss: 0.407286\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11.28, NNZs: 49, Bias: -4.000000, T: 234132, Avg. loss: 0.404721\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.31, NNZs: 49, Bias: -4.000000, T: 292665, Avg. loss: 0.407003\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 11.70, NNZs: 49, Bias: -4.000000, T: 351198, Avg. loss: 0.403117\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.91, NNZs: 49, Bias: -4.000000, T: 409731, Avg. loss: 0.403844\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10.85, NNZs: 49, Bias: -3.000000, T: 468264, Avg. loss: 0.408504\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 10.35, NNZs: 49, Bias: -4.000000, T: 526797, Avg. loss: 0.406112\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 10.93, NNZs: 49, Bias: -5.000000, T: 585330, Avg. loss: 0.406297\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.79, NNZs: 49, Bias: -5.000000, T: 643863, Avg. loss: 0.402200\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 8.77, NNZs: 49, Bias: -4.000000, T: 702396, Avg. loss: 0.405171\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 10.75, NNZs: 49, Bias: -4.000000, T: 760929, Avg. loss: 0.410071\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.85, NNZs: 49, Bias: -3.000000, T: 819462, Avg. loss: 0.406353\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 9.70, NNZs: 49, Bias: -4.000000, T: 877995, Avg. loss: 0.403778\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.63, NNZs: 49, Bias: -6.000000, T: 936528, Avg. loss: 0.402672\n",
      "Total training time: 0.29 seconds.\n",
      "Convergence after 16 epochs took 0.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47656063142788807"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if data is linearly seperable\n",
    "\n",
    "#if so then SVM, otherwise noisy SVM/kernels\n",
    "\n",
    "#one-vs-all\n",
    "\n",
    "#center data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(penalty=None, fit_intercept=True, max_iter=100000, tol=1e-5, verbose=1, shuffle=True, early_stopping=False) #centered data\n",
    "perceptron.fit(X_train, y_train)\n",
    "perceptron.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 49)\n",
      "11\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(perceptron.coef_.shape)\n",
    "print(perceptron.n_iter_)\n",
    "print(perceptron.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11546 / 25086\n"
     ]
    }
   ],
   "source": [
    "test_predictions = perceptron.predict(X_test)\n",
    "print(np.sum(test_predictions[:] == y_test[:, 0]), '/', test_predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "svc = LinearSVC(tol=1e-5, multi_class='ovr', verbose=1, random_state=0)\n",
    "clf = OneVsRestClassifier(svc).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 49)\n",
      "[[-1.00406974]\n",
      " [-0.17315056]\n",
      " [ 0.01531334]\n",
      " [-0.84345794]]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Attributes\n",
    "\n",
    "print(clf.coef_.shape)\n",
    "print(clf.intercept_)\n",
    "print(clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 2 2 2 1 2 2 1]\n",
      "[1 2 2 3 2 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test[0:10, :]))\n",
    "print(y_test[0:10, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model / Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\Documents\\GitHub\\traffic-accident-weather-analysis\\code\\module2_data\\GA\\SupportVectorMachines\n"
     ]
    }
   ],
   "source": [
    "save_dir = current_dir + '\\\\module2_data\\\\' + state + '\\\\SupportVectorMachines'\n",
    "print(save_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
